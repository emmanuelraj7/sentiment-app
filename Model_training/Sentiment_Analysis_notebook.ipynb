{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Sentiment Analysis on imdb dataset"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##### Dataset used: http://ai.stanford.edu/~amaas/data/sentiment/\n\n##### By: Emmanuel Raj, Jyothi Nandikonda, Naz Syeda"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 1: Import data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "reviews_train = []\nfor line in open('./Dataset/full_train.txt', 'r'):\n    reviews_train.append(line.strip())\n    \nreviews_test = []\nfor line in open('./Dataset/full_test.txt', 'r'):\n    reviews_test.append(line.strip())",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 2: Clean and Preprocess data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nREPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\nREPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n\ndef preprocess_reviews(reviews):\n    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n    \n    return reviews\n\nreviews_train_clean = preprocess_reviews(reviews_train)\nreviews_test_clean = preprocess_reviews(reviews_test)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(reviews_train_clean)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "25000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(reviews_test_clean)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "25000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 3: Vectorization"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(binary=True)\ncv.fit(reviews_train_clean)\nX = cv.transform(reviews_train_clean)\nX_test = cv.transform(reviews_test_clean)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#save cv as pkl file\n#import pickle\n#with open('/home/nbuser/library/vectorizer.pkl', 'wb') as model_pkl:\n#    pickle.dump(cv, model_pkl)\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 4: Build Sentiment analysis model and find best parameters"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##### Note: "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The targets/labels we use will be the same for training and testing because both datasets are structured the same, where the first 12.5k are positive and the last 12.5k are negative."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Ignore warnings on Jupyter notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ntarget = [1 if i < 12500 else 0 for i in range(25000)]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75\n)\n\n#Grid search for c value\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c)\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy for C=0.01: 0.8768\nAccuracy for C=0.05: 0.88864\nAccuracy for C=0.25: 0.88384\nAccuracy for C=0.5: 0.88096\nAccuracy for C=1: 0.8768\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 5.1: Train Final model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentiment = LogisticRegression(C=0.05)\nsentiment.fit(X, target)\nprint (\"Final Accuracy: %s\" \n       % accuracy_score(target, sentiment.predict(X_test)))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Final Accuracy: 0.88152\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "f1_score(y_val, sentiment.predict(X_val), average='macro') ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "0.9542395314128017"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 5.2: Training SVM classifier"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.svm import SVC",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clf_svc = SVC(gamma='auto')",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nclf_svc.fit(X_train, y_train) ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 12min 13s, sys: 365 ms, total: 12min 13s\nWall time: 12min 13s\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Accuracy for Support vector machine:   \"+str(accuracy_score(y_val, clf_svc.predict(X_val))))",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy for Support vector machine:   0.50064\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score\nf1_score(y_val, clf_svc.predict(X_val), average='macro') ",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "0.3350370021973224"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 5.3: Train Random Forrest Classifier"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nclf_rf.fit(X_train, y_train)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 1.2 s, sys: 9.91 ms, total: 1.21 s\nWall time: 1.21 s\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=2, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n            oob_score=False, random_state=0, verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Accuracy for random forrest:   \"+str(accuracy_score(y_val, clf_rf.predict(X_val))))",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy for random forrest:   0.7656\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score\nf1_score(y_val, clf_rf.predict(X_val), average='macro') ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "0.7648153729078457"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Check 5 most discriminating words for both positive and negative reviews"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "feature_to_coef = {\n    word: coef for word, coef in zip(\n        cv.get_feature_names(), sentiment.coef_[0]\n    )\n}\n\n#Best positive words\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:5]:\n    print (best_positive)\n    ",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "('excellent', 0.9292549017181694)\n('perfect', 0.7907005565370882)\n('great', 0.6745323515415729)\n('amazing', 0.6127039824916363)\n('superb', 0.6019368131550034)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Best negetive words\nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:5]:\n    print (best_negative)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "('worst', -1.3645958840794268)\n('waste', -1.166424244219479)\n('awful', -1.0324190211775237)\n('poorly', -0.8752018744646883)\n('boring', -0.8563543419889986)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 6: Predict using the model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred = sentiment.predict(cv.transform(['It was awful!']))",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "if pred == 0:\n    print(\"Negative\")\nelse: \n    print(\"Positive\")",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Negative\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 7: Function to predict sentiment of a given input"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def sentiment_predict(input):\n    pred = sentiment.predict(cv.transform([input]))\n    confidence_score = sentiment.predict_proba(cv.transform([input]))\n    if pred == 0:\n         output = \"Negative\" \n         confidence_score = float(\"{0:.2f}\".format(confidence_score[:,0][0]))\n    else: \n         output = \"Positive\"\n         confidence_score = float(\"{0:.2f}\".format(confidence_score[:,1][0]))\n    \n    return output, confidence_score\n    \n    ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentance = 'It was excellent!'",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentiment_predict(sentance)",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "('Positive', 0.74)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 8: Save the model as a serialized file"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#import pickle\n#with open('/home/nbuser/library/sentiment_model.pkl', 'wb') as model_pkl:\n#pickle.dump(sentiment, model_pkl)",
      "execution_count": 30,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}